{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb61c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import threading as thr\n",
    "import time\n",
    "import random as rand\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"london_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48937cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('london_weather.csv')\n",
    "\n",
    "# 1) drop any rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# 2) remove the 'date' column if it exists\n",
    "if 'date' in df_clean.columns:\n",
    "    df_clean = df_clean.drop(columns=['date'])\n",
    "\n",
    "df = df_clean.copy()\n",
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da28e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstmModel:\n",
    "  def __init__(self, alpha):\n",
    "    self.weights = np.zeros(6)            # 6 “weights”\n",
    "    self.grad    = np.zeros_like(self.weights)\n",
    "    self.alpha   = alpha\n",
    "\n",
    "  def zero_grad(self):\n",
    "    self.grad.fill(0.)\n",
    "\n",
    "  def train(self, chunk):\n",
    "    # 1) pretend our “model” is y_pred = X @ w\n",
    "    #    split chunk into X (6 features) and y (1 target)\n",
    "    X = chunk.iloc[:, :6].values           # shape (batch,6)\n",
    "    y = chunk.iloc[:, 6].values            # shape (batch,)\n",
    "\n",
    "    # 2) forward → MSE loss\n",
    "    y_pred = X.dot(self.weights)           # (batch,)\n",
    "    error  = y_pred - y                    # (batch,)\n",
    "    loss   = np.mean(error**2)             # scalar, not used further\n",
    "\n",
    "    # 3) backward → ∂(MSE)/∂w = (2/batch) * Xᵀ·error\n",
    "    self.zero_grad()\n",
    "    self.grad = (2.0 / X.shape[0]) * X.T.dot(error)  # shape (6,)\n",
    "\n",
    "    # simulate a bit of compute time\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 4) return that gradient vector\n",
    "    return self.grad\n",
    "  \n",
    "  def predict(self, data):\n",
    "    M = data.shape[0]\n",
    "    # simulate a prediction in [0,1)\n",
    "    return [rand.random() for _ in range(M)]\n",
    "  \n",
    "\n",
    "  def updateWeights(self):\n",
    "    self.weights -= self.alpha * self.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params\n",
    "N = 3\n",
    "grads = [None]*N\n",
    "models = [None]*N\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57825e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = np.array_split(df, N)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f50887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compBarrier = thr.Barrier(N+1)\n",
    "updateBarrier = thr.Barrier(N+1)\n",
    "\n",
    "def aggregate(grads):\n",
    "  return sum(grads) / len(grads)\n",
    "\n",
    "mutex = thr.Lock()\n",
    "def addGrad(i, grad):\n",
    "  print(\"THREAD\", i, \"IS CURRENTLY WAITING FOR THE `grads` MUTEX TO BE ACQUIRED...\")\n",
    "  mutex.acquire()\n",
    "  try: grads[i] = grad\n",
    "  finally: \n",
    "    mutex.release()\n",
    "    print(\"THREAD\", i, \"HAS RELEASED THE `grads` MUTEX...\")\n",
    "\n",
    "def worker(threadNum, chunk):\n",
    "  LSTMi = models[threadNum]\n",
    "  for epoch in range(epochs):\n",
    "    print(\"================================\")\n",
    "    grad = LSTMi.train(chunk)\n",
    "    addGrad(threadNum, grad)\n",
    "    print(\"THREAD:\", threadNum, \", EPOCH:\", epoch, \"GRAD:\", grad)\n",
    "    compBarrier.wait()\n",
    "    print(\"THREAD\", threadNum, \"is waiting for compBarrier. EPOCH:\", epoch)\n",
    "    updateBarrier.wait()\n",
    "    print(\"THREAD\", threadNum, \"is waiting for updateBarrier. EPOCH:\", epoch)\n",
    "    print(\"================================\")\n",
    "\n",
    "def controller():\n",
    "  M = df.shape[0]\n",
    "  chunks = np.array_split(df, N)\n",
    "  threads = []\n",
    "  for i, chunk in enumerate(chunks):\n",
    "    models[i] = lstmModel(0.01)\n",
    "    t = thr.Thread(target=worker, args=(i, chunk), daemon=True)\n",
    "    t.start()\n",
    "    print(\"Started thread\", i, \" using chunk\", i, \".\")\n",
    "    threads.append(t)\n",
    "    \n",
    "  for epoch in range(epochs):\n",
    "    print(\"================================\")\n",
    "    compBarrier.wait()           # wait for all workers to finish computing\n",
    "    newGrad = aggregate(grads)\n",
    "    print(\"[main] NEW GRAD:\", newGrad)\n",
    "    for m in models:\n",
    "      m.grad = newGrad        # or call m.updateWeights() if you stash grad there\n",
    "      m.updateWeights()\n",
    "    updateBarrier.wait()         # let workers continue to next epoch\n",
    "\n",
    "  for t in threads:\n",
    "      t.join()\n",
    "\n",
    "controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predictions\n",
    "predBarrier = thr.Barrier(N+1)\n",
    "allPreds = [None]*N\n",
    "\n",
    "predMutex = thr.Lock()\n",
    "def storePreds(i, preds):\n",
    "  print(\"THREAD\", i, \"IS CURRENTLY WAITING FOR THE `allPreds` MUTEX TO BE ACQUIRED...\")\n",
    "  predMutex.acquire()\n",
    "  try: allPreds[i] = preds\n",
    "  finally:\n",
    "    predMutex.release()\n",
    "    print(\"THREAD\", i, \"HAS RELEASED THE `allPreds` MUTEX...\")\n",
    "\n",
    "def predWorker(num, data):\n",
    "  model = models[num]\n",
    "  preds = model.predict(data)\n",
    "  print(\"THREAD\", num, \"has completed its predictions.\")\n",
    "  storePreds(num, preds)\n",
    "  print(\"THREAD\", num, \"is waiting for predBarrier.\")\n",
    "  predBarrier.wait() # wait for all threads to finish predictions\n",
    "  \n",
    "\n",
    "def predsCont(testSet):\n",
    "  M = testSet.shape[0]\n",
    "  threads = []\n",
    "  for i in range(N):\n",
    "    t = thr.Thread(target=predWorker, args=(i, testSet,), daemon=True)\n",
    "    t.start()\n",
    "    print(\"Started thread\", i, \" using chunk\", i, \".\")\n",
    "    threads.append(t)\n",
    "  \n",
    "  predBarrier.wait() # wait for all models to submit their predictions\n",
    "  \n",
    "  finalPreds = [None]*M\n",
    "\n",
    "  # using average voting\n",
    "  for predi in range(M):\n",
    "    predsForThisInstance = []\n",
    "    for modelsPreds in allPreds:\n",
    "      print(predi)\n",
    "      predsForThisInstance.append(modelsPreds[predi])\n",
    "    finalPreds[predi] = sum(predsForThisInstance)/len(predsForThisInstance)\n",
    "  for t in threads:\n",
    "    t.join()\n",
    "  return finalPreds\n",
    "\n",
    "test = df.sample(n=5, random_state=42)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "predsCont(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
